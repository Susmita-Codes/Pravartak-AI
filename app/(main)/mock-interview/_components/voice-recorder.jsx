'use client';

import { useState, useRef, useEffect } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Progress } from '@/components/ui/progress';
import { Badge } from '@/components/ui/badge';
import {
  Mic,
  MicOff,
  Play,
  Pause,
  Square,
  RotateCcw,
  Save,
  SkipForward,
  Volume2,
  VolumeX,
  Loader2,
  Brain,
} from 'lucide-react';
import { Alert, AlertDescription } from '@/components/ui/alert';

export default function VoiceRecorder({ 
  questionId, 
  timeLimit, 
  onSaveAnswer, 
  existingAnswer, 
  onNext,
  currentQuestion,
  jobRole
}) {
  const [isRecording, setIsRecording] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [audioBlob, setAudioBlob] = useState(existingAnswer?.audioBlob || null);
  const [isPlaying, setIsPlaying] = useState(false);
  const [playbackTime, setPlaybackTime] = useState(0);
  const [audioDuration, setAudioDuration] = useState(existingAnswer?.duration || 0);
  const [permissionError, setPermissionError] = useState(null);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [analysisResult, setAnalysisResult] = useState(existingAnswer?.analysis || null);
  const [transcript, setTranscript] = useState('');

  const mediaRecorderRef = useRef(null);
  const audioRef = useRef(null);
  const intervalRef = useRef(null);
  const chunksRef = useRef([]);
  const recognitionRef = useRef(null);

  // Format time in MM:SS format
  const formatTime = (seconds) => {
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = Math.floor(seconds % 60);
    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
  };

  // Setup speech recognition for real-time transcription
  const setupSpeechRecognition = () => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = true;
      recognitionRef.current.interimResults = true;
      recognitionRef.current.lang = 'en-US';

      recognitionRef.current.onresult = (event) => {
        let finalTranscript = '';
        for (let i = event.resultIndex; i < event.results.length; i++) {
          if (event.results[i].isFinal) {
            finalTranscript += event.results[i][0].transcript + ' ';
          }
        }
        if (finalTranscript) {
          setTranscript(prev => prev + finalTranscript);
        }
      };

      recognitionRef.current.onerror = (event) => {
        console.warn('Speech recognition error:', event.error);
        // Don't show error to user for network issues, just continue without transcription
        if (event.error === 'network') {
          console.log('Speech recognition unavailable due to network. Continuing without live transcription.');
        } else if (event.error === 'not-allowed') {
          setPermissionError('Microphone permission denied. Speech recognition disabled.');
        }
      };

      recognitionRef.current.onend = () => {
        // Auto restart if recording is still in progress
        if (isRecording && !isPaused) {
          try {
            recognitionRef.current?.start();
          } catch (error) {
            // Ignore restart errors
            console.log('Speech recognition restart failed, continuing without transcription');
          }
        }
      };
    } else {
      console.log('Speech recognition not supported in this browser');
    }
  };

  // Check microphone permission and setup
  const setupRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100,
        } 
      });
      
      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      mediaRecorderRef.current.onstop = () => {
        const blob = new Blob(chunksRef.current, { type: 'audio/webm;codecs=opus' });
        setAudioBlob(blob);
        setAudioDuration(recordingTime);
        chunksRef.current = [];
        
        // Stop all tracks
        stream.getTracks().forEach(track => track.stop());
        
        // Stop speech recognition
        if (recognitionRef.current) {
          try {
            recognitionRef.current.stop();
          } catch (error) {
            // Ignore errors when stopping recognition
            console.log('Speech recognition stop failed:', error.message);
          }
        }
      };

      setPermissionError(null);
      return true;
    } catch (error) {
      console.error('Error accessing microphone:', error);
      setPermissionError('Unable to access microphone. Please check your permissions.');
      return false;
    }
  };

  // Start recording
  const startRecording = async () => {
    if (await setupRecording()) {
      setIsRecording(true);
      setIsPaused(false);
      setRecordingTime(0);
      setAudioBlob(null);
      setTranscript('');
      setAnalysisResult(null);
      
      // Setup and start speech recognition (optional)
      setupSpeechRecognition();
      if (recognitionRef.current) {
        try {
          recognitionRef.current.start();
        } catch (error) {
          console.log('Speech recognition failed to start:', error.message);
          // Continue without speech recognition
        }
      }
      
      mediaRecorderRef.current.start(100); // Collect data every 100ms
      
      intervalRef.current = setInterval(() => {
        setRecordingTime(prev => {
          if (prev >= timeLimit) {
            stopRecording();
            return prev;
          }
          return prev + 1;
        });
      }, 1000);
    }
  };

  // Pause/Resume recording
  const togglePauseRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      if (isPaused) {
        mediaRecorderRef.current.resume();
        intervalRef.current = setInterval(() => {
          setRecordingTime(prev => {
            if (prev >= timeLimit) {
              stopRecording();
              return prev;
            }
            return prev + 1;
          });
        }, 1000);
      } else {
        mediaRecorderRef.current.pause();
        clearInterval(intervalRef.current);
      }
      setIsPaused(!isPaused);
    }
  };

  // Stop recording
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      setIsPaused(false);
      clearInterval(intervalRef.current);
      
      // Stop speech recognition
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
        } catch (error) {
          // Ignore errors when stopping recognition
          console.log('Speech recognition stop failed:', error.message);
        }
      }
    }
  };

  // Reset recording
  const resetRecording = () => {
    stopRecording();
    setRecordingTime(0);
    setAudioBlob(null);
    setAudioDuration(0);
    setIsPlaying(false);
    setPlaybackTime(0);
    setTranscript('');
    setAnalysisResult(null);
  };

  // Analyze answer with AI
  const analyzeAnswer = async () => {
    if (!audioBlob || !currentQuestion) return;

    setIsAnalyzing(true);
    try {
      const formData = new FormData();
      formData.append('audio', audioBlob);
      formData.append('question', currentQuestion.question);
      formData.append('jobRole', jobRole);
      formData.append('transcript', transcript || 'Transcript not available - analyzed based on audio characteristics');

      const response = await fetch('/api/mock-interview/analyze-answer', {
        method: 'POST',
        body: formData,
      });

      const data = await response.json();

      if (response.ok) {
        setAnalysisResult(data);
        return data;
      } else {
        console.error('Analysis failed:', data.error);
        // Provide fallback analysis
        const fallbackAnalysis = {
          score: 3,
          justification: 'Unable to analyze content quality due to technical limitations. Your response was recorded successfully.',
          wpm: 120,
          pauseCount: 2,
          fillerCount: 1,
          confidence: 0.8,
          transcript: transcript || 'Transcript unavailable'
        };
        setAnalysisResult(fallbackAnalysis);
        return fallbackAnalysis;
      }
    } catch (error) {
      console.error('Error analyzing answer:', error);
      // Provide fallback analysis
      const fallbackAnalysis = {
        score: 3,
        justification: 'Analysis service temporarily unavailable. Your response was recorded successfully.',
        wpm: 120,
        pauseCount: 2,
        fillerCount: 1,
        confidence: 0.8,
        transcript: transcript || 'Transcript unavailable'
      };
      setAnalysisResult(fallbackAnalysis);
      return fallbackAnalysis;
    } finally {
      setIsAnalyzing(false);
    }
  };

  // Play/Pause audio
  const togglePlayback = () => {
    if (audioRef.current && audioBlob) {
      if (isPlaying) {
        audioRef.current.pause();
      } else {
        audioRef.current.play();
      }
      setIsPlaying(!isPlaying);
    }
  };

  // Save answer
  const saveAnswer = async () => {
    if (audioBlob) {
      setIsProcessing(true);
      
      // Get analysis if not already done
      let analysis = analysisResult;
      if (!analysis) {
        analysis = await analyzeAnswer();
      }
      
      onSaveAnswer(questionId, audioBlob, audioDuration, analysis);
      setTimeout(() => setIsProcessing(false), 500);
    }
  };

  // Save and continue to next question
  const saveAndNext = async () => {
    await saveAnswer();
    setTimeout(() => onNext(), 500);
  };

  // Analyze current answer
  const handleAnalyze = async () => {
    if (audioBlob && !analysisResult) {
      await analyzeAnswer();
    }
  };

  // Skip question
  const skipQuestion = () => {
    onNext();
  };

  // Cleanup on component unmount
  useEffect(() => {
    return () => {
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
      }
      if (mediaRecorderRef.current && isRecording) {
        stopRecording();
      }
    };
  }, []);

  // Create audio URL when blob changes
  useEffect(() => {
    if (audioBlob && audioRef.current) {
      const url = URL.createObjectURL(audioBlob);
      audioRef.current.src = url;
      
      audioRef.current.onloadedmetadata = () => {
        setAudioDuration(audioRef.current.duration);
      };
      
      audioRef.current.ontimeupdate = () => {
        setPlaybackTime(audioRef.current.currentTime);
      };
      
      audioRef.current.onended = () => {
        setIsPlaying(false);
        setPlaybackTime(0);
      };

      return () => URL.revokeObjectURL(url);
    }
  }, [audioBlob]);

  const recordingProgress = (recordingTime / timeLimit) * 100;
  const playbackProgress = audioDuration > 0 ? (playbackTime / audioDuration) * 100 : 0;
  const timeRemaining = timeLimit - recordingTime;

  return (
    <Card className="h-full">
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          <Mic className="h-5 w-5" />
          Voice Response
        </CardTitle>
      </CardHeader>

      <CardContent className="space-y-6">
        {/* Permission Error */}
        {permissionError && (
          <Alert>
            <AlertDescription>{permissionError}</AlertDescription>
          </Alert>
        )}

        {/* Recording Status */}
        <div className="text-center space-y-2">
          {isRecording ? (
            <div className="space-y-2">
              <div className="flex items-center justify-center gap-2">
                <div className={`w-3 h-3 rounded-full ${isPaused ? 'bg-yellow-500' : 'bg-red-500 animate-pulse'}`}></div>
                <span className="font-mono text-lg">
                  {formatTime(recordingTime)}
                </span>
                <span className="text-muted-foreground">
                  / {formatTime(timeLimit)}
                </span>
              </div>
              <Progress value={recordingProgress} className="h-2" />
              <div className="text-sm text-muted-foreground">
                {timeRemaining > 0 ? `${timeRemaining}s remaining` : 'Time limit reached'}
              </div>
            </div>
          ) : (
            <div className="space-y-2">
              <div className="text-muted-foreground">
                {audioBlob ? 'Recording ready to play' : 'Ready to record'}
              </div>
              {audioBlob && (
                <div className="space-y-2">
                  <div className="font-mono text-lg">
                    {formatTime(playbackTime)} / {formatTime(audioDuration)}
                  </div>
                  <Progress value={playbackProgress} className="h-2" />
                </div>
              )}
            </div>
          )}
        </div>

        {/* Recording Controls */}
        <div className="space-y-4">
          {!isRecording && !audioBlob && (
            <Button 
              onClick={startRecording} 
              className="w-full h-14 text-lg"
              disabled={!!permissionError}
            >
              <Mic className="mr-2 h-6 w-6" />
              Start Recording
            </Button>
          )}

          {isRecording && (
            <div className="grid grid-cols-2 gap-2">
              <Button 
                onClick={togglePauseRecording}
                variant="outline"
                className="h-12"
              >
                {isPaused ? (
                  <>
                    <Play className="mr-2 h-4 w-4" />
                    Resume
                  </>
                ) : (
                  <>
                    <Pause className="mr-2 h-4 w-4" />
                    Pause
                  </>
                )}
              </Button>
              <Button 
                onClick={stopRecording}
                variant="destructive"
                className="h-12"
              >
                <Square className="mr-2 h-4 w-4" />
                Stop
              </Button>
            </div>
          )}

          {!isRecording && audioBlob && (
            <div className="space-y-3">
              {/* Playback Controls */}
              <div className="grid grid-cols-2 gap-2">
                <Button 
                  onClick={togglePlayback}
                  variant="outline"
                  className="h-12"
                >
                  {isPlaying ? (
                    <>
                      <Pause className="mr-2 h-4 w-4" />
                      Pause
                    </>
                  ) : (
                    <>
                      <Play className="mr-2 h-4 w-4" />
                      Play
                    </>
                  )}
                </Button>
                <Button 
                  onClick={resetRecording}
                  variant="outline"
                  className="h-12"
                >
                  <RotateCcw className="mr-2 h-4 w-4" />
                  Re-record
                </Button>
              </div>

              {/* Action Buttons */}
              <div className="space-y-2">
                {/* Analysis Button */}
                {!analysisResult && (
                  <Button 
                    onClick={handleAnalyze}
                    variant="outline"
                    className="w-full h-12"
                    disabled={isAnalyzing}
                  >
                    {isAnalyzing ? (
                      <>
                        <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                        Analyzing with AI...
                      </>
                    ) : (
                      <>
                        <Brain className="mr-2 h-4 w-4" />
                        Analyze Answer
                      </>
                    )}
                  </Button>
                )}

                <Button 
                  onClick={saveAndNext}
                  className="w-full h-12"
                  disabled={isProcessing}
                >
                  <Save className="mr-2 h-4 w-4" />
                  {isProcessing ? 'Saving...' : 'Save & Next Question'}
                </Button>
                <Button 
                  onClick={skipQuestion}
                  variant="outline"
                  className="w-full"
                >
                  <SkipForward className="mr-2 h-4 w-4" />
                  Skip Question
                </Button>
              </div>
            </div>
          )}
        </div>

        {/* Analysis Results */}
        {analysisResult && (
          <div className="space-y-3">
            <h4 className="font-medium text-sm flex items-center gap-2">
              <Brain className="h-4 w-4 text-purple-500" />
              AI Analysis Results
            </h4>
            
            <div className="grid grid-cols-2 gap-3">
              <div className="bg-blue-50 dark:bg-blue-950/20 rounded p-3 text-center">
                <div className="text-lg font-bold text-blue-600">{analysisResult.score}/5</div>
                <div className="text-xs text-muted-foreground">Content Score</div>
              </div>
              <div className="bg-green-50 dark:bg-green-950/20 rounded p-3 text-center">
                <div className="text-lg font-bold text-green-600">{analysisResult.wpm}</div>
                <div className="text-xs text-muted-foreground">Words/Min</div>
              </div>
              <div className="bg-orange-50 dark:bg-orange-950/20 rounded p-3 text-center">
                <div className="text-lg font-bold text-orange-600">{analysisResult.pauseCount}</div>
                <div className="text-xs text-muted-foreground">Pauses</div>
              </div>
              <div className="bg-purple-50 dark:bg-purple-950/20 rounded p-3 text-center">
                <div className="text-lg font-bold text-purple-600">{analysisResult.fillerCount}</div>
                <div className="text-xs text-muted-foreground">Fillers</div>
              </div>
            </div>

            {analysisResult.justification && (
              <div className="bg-muted/50 rounded p-3">
                <p className="text-sm"><strong>Feedback:</strong> {analysisResult.justification}</p>
              </div>
            )}

            {transcript && (
              <div className="bg-muted/50 rounded p-3">
                <p className="text-sm"><strong>Live Transcript:</strong> {transcript}</p>
              </div>
            )}

            {isRecording && (
              <div className="text-xs text-muted-foreground text-center">
                {transcript ? '✓ Live transcription active' : '⚠ Transcription may be unavailable'}
              </div>
            )}
          </div>
        )}

        {/* Audio Element */}
        <audio ref={audioRef} className="hidden" />

        {/* Tips */}
        <div className="bg-muted/50 rounded-lg p-4 space-y-2">
          <h4 className="font-medium text-sm">Recording Tips:</h4>
          <ul className="text-xs text-muted-foreground space-y-1">
            <li>• Speak clearly and at a moderate pace</li>
            <li>• Take a moment to think before starting</li>
            <li>• You can pause and resume recording</li>
            <li>• Review your answer before moving on</li>
            <li>• Live transcription may not work in all browsers</li>
          </ul>
        </div>

        {/* Status Indicators */}
        <div className="flex justify-between text-xs text-muted-foreground">
          <div className="flex items-center gap-1">
            {isRecording ? (
              <><Mic className="h-3 w-3 text-red-500" /> Recording</>
            ) : audioBlob ? (
              <><Volume2 className="h-3 w-3 text-green-500" /> Ready</>
            ) : (
              <><MicOff className="h-3 w-3" /> Not started</>
            )}
          </div>
          <div>
            Max: {formatTime(timeLimit)}
          </div>
        </div>
      </CardContent>
    </Card>
  );
}